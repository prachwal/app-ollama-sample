# Ollama Advanced Testing Suite ğŸš€

**Kompleksowy system testowania modeli LLM z interfejsem graficznym i wielojÄ™zycznÄ… obsÅ‚ugÄ…**

[![Python 3.7+](https://img.shields.io/badge/python-3.7+-blue.svg)](https://www.python.org/downloads/)
[![Ollama](https://img.shields.io/badge/Ollama-Compatible-green.svg)](https://ollama.ai/)
[![GUI](https://img.shields.io/badge/GUI-Tkinter-orange.svg)](https://docs.python.org/3/library/tkinter.html)

## ğŸ“‹ PrzeglÄ…d projektu

Zaawansowana platforma do testowania i porÃ³wnywania modeli LLM z obsÅ‚ugÄ… Ollama API. Oferuje zarÃ³wno graficzny jak i konsolowy interfejs uÅ¼ytkownika z funkcjami automatyzacji, wielojÄ™zycznoÅ›ci i szczegÃ³Å‚owej analizy wynikÃ³w.

### ğŸŒŸ GÅ‚Ã³wne funkcjonalnoÅ›ci

- ğŸ’¬ **Interaktywny chat** z modelami LLM
- ğŸ§ª **Komprehensywne testy** z ocenÄ… AI sÄ™dziego (Gemini)
- ğŸŒ **ObsÅ‚uga wielojÄ™zyczna** (Polski/English)
- ğŸ“Š **Analiza i filtrowanie** modeli po parametrach
- ğŸ¨ **Graficzny interfejs uÅ¼ytkownika** (Tkinter)
- ğŸ” **System eksportu** wynikÃ³w (JSON/CSV/Markdown)
- ğŸ§¹ **Automatyczne czyszczenie** projektu
- ğŸ“ **ModuÅ‚owa architektura** dla Å‚atwego rozwoju

## ğŸš€ Szybki Start

### 1. Uruchomienie GUI (Zalecane)
```bash
# Metoda 1: Plik wsadowy Windows
start_gui.bat

# Metoda 2: Python launcher
python launch_gui.py

# Metoda 3: BezpoÅ›rednio
python ollama_basic_chat_gui.py
```

### 2. Uruchomienie CLI wielojÄ™zycznego
```bash
python ollama_multilingual_cli.py
```

### 3. Czyszczenie projektu
```powershell
# PowerShell - zaawansowany z opcjami
.\cleanup.ps1 -DryRun        # PodglÄ…d
.\cleanup.ps1 -Force         # Automatyczne

# PowerShell - szybki
.\quick-cleanup.ps1

# Windows Batch
cleanup.bat
```

## ğŸ—ï¸ Architektura Projektu

```
app-ollama-sample/
â”œâ”€â”€ ğŸ¨ GUI APLIKACJE
â”‚   â”œâ”€â”€ ollama_basic_chat_gui.py      # GÅ‚Ã³wny interfejs graficzny
â”‚   â”œâ”€â”€ launch_gui.py                 # Launcher z walidacjÄ…
â”‚   â””â”€â”€ start_gui.bat                # Windows starter
â”‚
â”œâ”€â”€ ğŸ’» CLI APLIKACJE  
â”‚   â””â”€â”€ ollama_multilingual_cli.py    # WielojÄ™zyczny interfejs konsolowy
â”‚
â”œâ”€â”€ ğŸ§¹ AUTOMATYZACJA
â”‚   â”œâ”€â”€ cleanup.ps1                   # Zaawansowane czyszczenie PowerShell
â”‚   â”œâ”€â”€ quick-cleanup.ps1            # Szybkie czyszczenie PowerShell
â”‚   â””â”€â”€ cleanup.bat                  # Czyszczenie Windows Batch
â”‚
â”œâ”€â”€ ğŸ“ MODUÅOWA ARCHITEKTURA
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ api/                     # Klienty API (Ollama, Gemini)
â”‚       â”œâ”€â”€ utils/                   # NarzÄ™dzia i prompty testowe
â”‚       â”œâ”€â”€ testers/                 # ModuÅ‚y testowe
â”‚       â””â”€â”€ config.py               # Centralna konfiguracja
â”‚
â”œâ”€â”€ ğŸ“š DOKUMENTACJA
â”‚   â”œâ”€â”€ README.md                    # Ten plik - gÅ‚Ã³wny przeglÄ…d
â”‚   â”œâ”€â”€ README_GUI.md               # SzczegÃ³Å‚y interfejsu graficznego
â”‚   â”œâ”€â”€ README_MULTILINGUAL.md      # WielojÄ™zycznoÅ›Ä‡ i testy
â”‚   â”œâ”€â”€ README_CLEANUP.md           # Skrypty czyszczenia
â”‚   â”œâ”€â”€ README_FILTERING.md         # Filtrowanie modeli
â”‚   â””â”€â”€ README_REFACTORING.md       # Historia refaktoryzacji
â”‚
â””â”€â”€ âš™ï¸ KONFIGURACJA
    â”œâ”€â”€ .gitignore                  # Ignorowane pliki Git
    â”œâ”€â”€ .vscode/launch.json         # Konfiguracja debug VS Code
    â””â”€â”€ cache/                      # Cache metadanych modeli
```

## ğŸ¯ Aplikacje i NarzÄ™dzia

### ğŸ¨ GUI - Interfejs Graficzny

**Plik:** `ollama_basic_chat_gui.py`

**FunkcjonalnoÅ›ci:**
- âœ… **ZakÅ‚adki** dla rÃ³Å¼nych funkcji (Chat/Testy)
- âœ… **ğŸ†• Tryby systemowe** - 9 predefiniowanych persona + wÅ‚asne prompty
- âœ… **WybÃ³r jÄ™zyka testÃ³w** (Polski/English dropdown)
- âœ… **Interaktywny chat** z wybranymi modelami
- âœ… **Testy szybkie i kompletne** z paskiem postÄ™pu
- âœ… **ZarzÄ…dzanie plikami** chat'Ã³w (zapis/odczyt)
- âœ… **Monitoring w czasie rzeczywistym** testÃ³w
- âœ… **Status przerwania testÃ³w** z przyciskiem Stop

```bash
python ollama_basic_chat_gui.py
```

### ğŸ’» CLI - WielojÄ™zyczny Interfejs Konsolowy

**Plik:** `ollama_multilingual_cli.py`

**FunkcjonalnoÅ›ci:**
- âœ… **WybÃ³r jÄ™zyka przy starcie** (Polski/English)
- âœ… **13 testÃ³w komprehensywnych** w wybranym jÄ™zyku
- âœ… **6 testÃ³w szybkich** dla podstawowej oceny
- âœ… **WÅ‚asne pytania** do wszystkich modeli jednoczeÅ›nie
- âœ… **Ocena AI sÄ™dziego** (Gemini) z punktacjÄ… 1-10
- âœ… **Eksport wynikÃ³w** do plikÃ³w z timestamp

```bash
python ollama_multilingual_cli.py
```

### ğŸ” Filtrowanie Modeli

**FunkcjonalnoÅ›Ä‡:** Znajdowanie modeli o podobnych parametrach

```bash
# Filtruj podobne do gemma2:2b (domyÅ›lnie)
python -c "from src.utils.model_filter import filter_similar_models; filter_similar_models()"

# WyÅ›wietl wszystkie dostÄ™pne modele
python -c "from src.api.ollama_client import get_available_models; print(get_available_models())"
```

**Kryteria filtrowania:**
- **Rozmiar pliku**: Â±0.5 GB
- **Liczba parametrÃ³w**: Â±1B
- **DÅ‚ugoÅ›Ä‡ kontekstu**: Â±50,000 tokenÃ³w  
- **Liczba warstw**: Â±5 warstw

## ğŸŒ WielojÄ™zycznoÅ›Ä‡

### ObsÅ‚ugiwane jÄ™zyki testÃ³w:
- ğŸ‡µğŸ‡± **Polski** - Oryginalny zestaw 19 testÃ³w
- ğŸ‡¬ğŸ‡§ **English** - PeÅ‚ne tÅ‚umaczenia wszystkich testÃ³w

### Typy testÃ³w:
1. **Testy komprehensywne** (13): Matematyka, Logika, KreatywnoÅ›Ä‡, Programowanie, Etyka AI, itp.
2. **Testy szybkie** (6): Podstawowe zadania dla szybkiej oceny
3. **WÅ‚asne pytania**: Zadawanie dowolnych pytaÅ„ wszystkim modelom

### Ocena wynikÃ³w:
- **AI SÄ™dzia**: Gemini-1.5-flash ocenia odpowiedzi w skali 1-10
- **SzczegÃ³Å‚owa analiza**: Mocne i sÅ‚abe strony kaÅ¼dego modelu
- **Ranking modeli**: Sortowanie wedÅ‚ug Å›redniej punktacji

## ğŸ§¹ Automatyzacja i Czyszczenie

### PowerShell (Zaawansowany)
```powershell
.\cleanup.ps1 -DryRun     # PodglÄ…d bez usuwania
.\cleanup.ps1             # Interaktywne czyszczenie
.\cleanup.ps1 -Force      # Automatyczne bez pytaÅ„
```

### PowerShell (Szybki)
```powershell
.\quick-cleanup.ps1       # Szybkie czyszczenie bez opcji
```

### Windows Batch
```cmd
cleanup.bat               # Kompatybilny z wszystkimi Windows
```

**Co usuwa:**
- âœ… Cache Python (`__pycache__`, `.pyc`)
- âœ… Pliki testÃ³w (`*test*.txt`, `chat_*.txt`)
- âœ… Pliki tymczasowe (`.tmp`, `.bak`, `.old`)
- âœ… Pliki systemu (`.DS_Store`, `Thumbs.db`)
- âœ… Cache IDE (`.vscode/settings.json`, `*.swp`)

## âš™ï¸ Konfiguracja

### Wymagania systemowe:
- **Python 3.7+**
- **Tkinter** (wbudowany w Python)
- **DziaÅ‚ajÄ…cy serwer Ollama** (`http://localhost:11434`)
- **Klucz API Gemini** (dla funkcji sÄ™dziego AI)

### Konfiguracja Å›rodowiska:
```bash
# Ustaw klucz API Gemini (opcjonalne)
export GEMINI_API_KEY="your-api-key-here"

# Lub ustaw w pliku .env
echo "GEMINI_API_KEY=your-api-key-here" > .env
```

### Centralna konfiguracja (`src/config.py`):
```python
OLLAMA_API_URL = "http://localhost:11434"
GEMINI_JUDGE_MODEL_NAME = "gemini-1.5-flash"
DEFAULT_TIMEOUT_PER_MODEL = 180
DEFAULT_SLEEP_BETWEEN_MODELS = 2
```

## ğŸ“Š PrzykÅ‚adowe wyniki

### Test wielojÄ™zyczny (Polski):
```
ğŸ“Š WYNIKI TESTÃ“W KOMPREHENSYWNYCH:
====================================
ğŸ¥‡ qwen2.5:7b        - Åšrednia: 8.2/10 (DoskonaÅ‚y)
ğŸ¥ˆ llama3.2:3b       - Åšrednia: 7.8/10 (Bardzo dobry)  
ğŸ¥‰ gemma2:2b         - Åšrednia: 7.1/10 (Dobry)

ğŸ’ NAJLEPSZE WYNIKI:
- Matematyka: qwen2.5:7b (9.5/10)
- KreatywnoÅ›Ä‡: llama3.2:3b (9.0/10)
- Programowanie: qwen2.5:7b (8.8/10)
```

### Filtrowanie modeli:
```
ğŸ“‹ MODELE PODOBNE DO gemma2:2b:
================================
1. qwen3:1.7b         - PodobieÅ„stwo: 4/4 (DoskonaÅ‚e)
2. llama3.2:3b        - PodobieÅ„stwo: 3/4 (Bardzo dobre)
3. qwen2.5-coder:1.5b - PodobieÅ„stwo: 2/4 (Dobre)
```

## ğŸ› ï¸ RozwÃ³j i Rozszerzanie

### Dodawanie nowych testÃ³w:
```python
# src/utils/test_prompts.py (polski)
COMPREHENSIVE_TESTS = {
    "nowy_test": {
        "prompt": "TwÃ³j prompt testowy...",
        "judge_prompt": "Kryteria oceny...",
        "category": "Kategoria"
    }
}

# src/utils/multilingual_prompts.py (angielski)
COMPREHENSIVE_TESTS_EN = {
    "new_test": {
        "prompt": "Your test prompt...",
        "judge_prompt": "Evaluation criteria...",
        "category": "Category"
    }
}
```

### Dodawanie nowych testerÃ³w:
```python
from src.testers.base_tester import BaseTester

class MyCustomTester(BaseTester):
    def run_custom_test(self):
        # Twoja implementacja
        pass
```

## ğŸ¤ WkÅ‚ad w projekt

MiÅ‚e widziane:
- ğŸ› **ZgÅ‚aszanie bÅ‚Ä™dÃ³w** via Issues
- âœ¨ **Propozycje funkcjonalnoÅ›ci**
- ğŸ”§ **Pull requesty** z poprawkami
- ğŸ“š **Udoskonalenia dokumentacji**
- ğŸŒ **TÅ‚umaczenia** na nowe jÄ™zyki

## ğŸ“‹ Roadmapa

### ğŸ”„ W trakcie:
- [ ] **Baza danych** dla historii testÃ³w
- [ ] **Tematy UI** (ciemny/jasny)
- [ ] **Wykres wydajnoÅ›ci** modeli
- [ ] **API REST** dla zdalnych testÃ³w

### ğŸ”® Planowane:
- [ ] **Docker containers** dla Å‚atwego wdroÅ¼enia
- [ ] **Plugin system** dla rozszerzeÅ„
- [ ] **Web dashboard** React/Vue
- [ ] **Integracja z MLflow** dla Å›ledzenia eksperymentÃ³w
- [ ] **Rozproszone testy** na wielu maszynach

## ğŸ†˜ RozwiÄ…zywanie problemÃ³w

### GUI siÄ™ nie uruchamia:
```bash
python -c "import tkinter; print('Tkinter OK')"
```

### Brak modeli Ollama:
```bash
# SprawdÅº status Ollama
curl http://localhost:11434/api/tags

# Pobierz model testowy
ollama pull gemma2:2b
```

### BÅ‚Ä™dy API Gemini:
```bash
# SprawdÅº klucz API
echo $GEMINI_API_KEY

# Test poÅ‚Ä…czenia
python -c "from src.api.gemini_client import test_connection; test_connection()"
```

---

## ğŸ“„ Licencja

MIT License - Zobacz plik LICENSE dla szczegÃ³Å‚Ã³w.

## ğŸ™ PodziÄ™kowania

- **Ollama** - Za doskonaÅ‚e API i modele LLM
- **Google Gemini** - Za inteligentnÄ… ocenÄ™ wynikÃ³w
- **SpoÅ‚ecznoÅ›Ä‡ Open Source** - Za inspiracjÄ™ i wsparcie

---

**ğŸ’¡ Tip:** Dla najlepszych wynikÃ³w upewnij siÄ™, Å¼e Ollama jest uruchomiony z zaÅ‚adowanymi modelami przed rozpoczÄ™ciem testÃ³w.

**ğŸ“ Wsparcie:** JeÅ›li masz pytania lub problemy, sprawdÅº dokumentacjÄ™ w plikach `README_*.md` lub utwÃ³rz Issue w repozytorium.
